{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599, 41)\n",
      "(400, 40)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "train = pd.read_csv('~/Downloads/train.csv')\n",
    "test = pd.read_csv('~/Downloads/test.csv')\n",
    "y_train = train['Label']\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#na_cols = train.columns[train.isna().any()].tolist()\n",
    "#na_cols = test.columns[test.isna().any()].tolist()\n",
    "# Fill missing scores using mean\n",
    "score_values = train[['I1','I2','I3','I4','I5','I6','I7','I8','I9','I10','I11','I12','I13']].mean()\n",
    "train = train.fillna(score_values)\n",
    "test = test.fillna(score_values)\n",
    "# Fill missing catagorical data using 'NotSpecific'\n",
    "cols = ['C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11','C12', 'C13','C14','C15','C16','C17','C18','C19','C20','C21','C22','C23','C24','C25','C26']\n",
    "train = train.fillna({k: 'NotSpecified' for k in cols})\n",
    "test = test.fillna({k: 'NotSpecified' for k in cols})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1599, 13104)\n",
      "(400, 13104)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>I10</th>\n",
       "      <th>...</th>\n",
       "      <th>C26_ed9e6b03</th>\n",
       "      <th>C26_68d9ada1</th>\n",
       "      <th>C26_9a333cac</th>\n",
       "      <th>C26_abc00283</th>\n",
       "      <th>C26_8fa55041</th>\n",
       "      <th>C26_a6dec5b6</th>\n",
       "      <th>C26_491eeeef</th>\n",
       "      <th>C26_8f9d38b3</th>\n",
       "      <th>C26_80dd0a5b</th>\n",
       "      <th>C26_7132fed8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.515487</td>\n",
       "      <td>-1</td>\n",
       "      <td>35.562802</td>\n",
       "      <td>7.921739</td>\n",
       "      <td>8020.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.55531</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 13104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         I1  I2         I3        I4      I5    I6   I7   I8    I9      I10  \\\n",
       "0  3.515487  -1  35.562802  7.921739  8020.0  26.0  6.0  0.0  80.0  0.55531   \n",
       "\n",
       "   ...  C26_ed9e6b03  C26_68d9ada1  C26_9a333cac  C26_abc00283  C26_8fa55041  \\\n",
       "0  ...             0             0             0             0             0   \n",
       "\n",
       "   C26_a6dec5b6  C26_491eeeef  C26_8f9d38b3  C26_80dd0a5b  C26_7132fed8  \n",
       "0             0             0             0             0             0  \n",
       "\n",
       "[1 rows x 13104 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def set_unique_categories(category_columns, train, test):\n",
    "    \"\"\"\n",
    "    Set unique categories (include both in training and testing data) for each column so we can do one hot encoding\n",
    "    @Param category_columns: column name\n",
    "    @Param train: training data\n",
    "    @Param test: testing data\n",
    "    \"\"\"\n",
    "    for column in category_columns:\n",
    "        unique_elements = pd.concat([train[column],test[column]]).unique().tolist()\n",
    "        train[column] = train[column].astype('category').cat.set_categories(unique_elements)\n",
    "        test[column] = test[column].astype('category').cat.set_categories(unique_elements)\n",
    "        \n",
    "# One hot encoding \n",
    "category_columns = {'C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11','C12', 'C13','C14','C15','C16','C17','C18','C19','C20','C21','C22','C23','C24','C25','C26'}\n",
    "set_unique_categories(category_columns, train, test)\n",
    "one_hot_train = pd.get_dummies(train)\n",
    "one_hot_test = pd.get_dummies(test)\n",
    "\n",
    "x_train = one_hot_train.drop(['Id','Label'], axis=1)\n",
    "x_test = one_hot_test.drop(['Id'], axis=1)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "x_test.head(1)                            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mingxie/.pyenv/versions/3.7.0/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Users/mingxie/.pyenv/versions/3.7.0/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "/Users/mingxie/.pyenv/versions/3.7.0/lib/python3.7/site-packages/ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mingxie/.pyenv/versions/3.7.0/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#clf = LogisticRegression(random_state=0, C=0.25, class_weight={0: 1, 1: 10}).fit(x_train, y_train)\n",
    "#clf = LogisticRegression().fit(x_train, y_train)\n",
    "#clf = SGDClassifier().fit(x_train, y_train)\n",
    "#clf = LinearSVC().fit(x_train, y_train)\n",
    "#clf = DecisionTreeClassifier().fit(x_train, y_train)\n",
    "#clf = GradientBoostingClassifier().fit(x_train, y_train)\n",
    "clf = RandomForestClassifier().fit(x_train, y_train)\n",
    "pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('~/Downloads/submission.csv')\n",
    "submission['Label'] = pred\n",
    "submission.to_csv('~/Downloads/forest_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
